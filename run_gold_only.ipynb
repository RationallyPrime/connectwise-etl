{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Gold Layer Processing Only\n",
    "\n",
    "This notebook creates fact and dimension tables from existing silver tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install the Wheel Files (if not already installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the wheel files (skip if already installed)\n",
    "%pip install /lakehouse/default/Files/dist/unified_etl_core-1.0.0-py3-none-any.whl\n",
    "%pip install /lakehouse/default/Files/dist/unified_etl_connectwise-1.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "from unified_etl_core.main import run_etl_pipeline\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\nprint(\"ðŸ¥‡ Starting Gold Layer Processing...\")\nprint(\"This will create fact tables with surrogate keys and business metrics\")\n\n# Build table mappings for schema-enabled lakehouse\ntable_mappings = {\n    \"silver\": silver_table_mapping,  # From previous cell\n    \"gold\": {}\n}\n\n# Add gold table mappings\nfor entity_name in silver_table_mapping.keys():\n    table_mappings[\"gold\"][entity_name] = f\"gold.gold_cw_{entity_name}\"\n\n# Create entity configurations for gold processing\n# Fix the format - calculated_columns should be a dict, not a list\nentity_configs = {\n    \"agreement\": {\n        \"source\": \"connectwise\",\n        \"surrogate_keys\": [\n            {\"name\": \"AgreementSK\", \"business_keys\": [\"id\"]}\n        ],\n        \"business_keys\": [\n            {\"name\": \"AgreementBusinessKey\", \"source_columns\": [\"id\"]}\n        ],\n        \"calculated_columns\": {\n            \"estimated_monthly_revenue\": \"CASE WHEN applicationUnits = 'Amount' THEN COALESCE(applicationLimit, 0) ELSE 0 END\"\n        }\n    }\n}\n\n# Add basic configs for other entities\nfor entity in silver_table_mapping.keys():\n    if entity not in entity_configs:\n        entity_configs[entity] = {\n            \"source\": \"connectwise\",\n            \"surrogate_keys\": [\n                {\"name\": f\"{entity.title()}SK\", \"business_keys\": [\"id\"]}\n            ],\n            \"business_keys\": [\n                {\"name\": f\"{entity.title()}BusinessKey\", \"source_columns\": [\"id\"]}\n            ],\n            \"calculated_columns\": {}  # Empty dict, not list\n        }\n\nconfig = {\"entities\": entity_configs}\n\nprint(f\"Processing entities: {list(entity_configs.keys())}\")\n\n# Run Gold layer with proper table mappings\nrun_etl_pipeline(\n    integrations=[\"connectwise\"],\n    layers=[\"gold\"],\n    config=config,\n    table_mappings=table_mappings\n)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List silver tables in silver schema\n",
    "silver_tables = spark.sql(\"SHOW TABLES IN silver\").collect()\n",
    "print(f\"Found {len(silver_tables)} tables in silver schema:\")\n",
    "\n",
    "# Build silver table mapping and show counts\n",
    "silver_table_mapping = {}\n",
    "for row in silver_tables:\n",
    "    table_name = row.tableName\n",
    "    full_table_name = f\"silver.{table_name}\"\n",
    "    count = spark.sql(f\"SELECT COUNT(*) FROM {full_table_name}\").collect()[0][0]\n",
    "    print(f\"  - {full_table_name}: {count:,} rows\")\n",
    "    \n",
    "    # Extract entity name (e.g., silver_cw_agreement -> agreement)\n",
    "    entity_name = table_name.replace(\"silver_cw_\", \"\")\n",
    "    silver_table_mapping[entity_name] = full_table_name\n",
    "\n",
    "print(f\"\\nEntities to process: {list(silver_table_mapping.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Gold Layer Processing\n",
    "\n",
    "Create fact tables with business logic:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "from unified_etl_core.main import run_etl_pipeline\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\nprint(\"ðŸ¥‡ Starting Gold Layer Processing...\")\nprint(\"This will create fact tables with business logic\")\n\n# Build table mappings for schema-enabled lakehouse\ntable_mappings = {\n    \"silver\": silver_table_mapping,  # From previous cell\n    \"gold\": {}\n}\n\n# Add gold table mappings - these will be used for the fact tables created\nfor entity_name in silver_table_mapping.keys():\n    table_mappings[\"gold\"][f\"fact_{entity_name}\"] = f\"gold.gold_cw_fact_{entity_name}\"\n    \n# Also add mappings for specialized fact tables\ntable_mappings[\"gold\"][\"fact_agreement_period\"] = \"gold.gold_cw_fact_agreement_period\"\ntable_mappings[\"gold\"][\"fact_agreement_summary\"] = \"gold.gold_cw_fact_agreement_summary\"\ntable_mappings[\"gold\"][\"fact_invoice_line\"] = \"gold.gold_cw_fact_invoice_line\"\ntable_mappings[\"gold\"][\"fact_invoice_header\"] = \"gold.gold_cw_fact_invoice_header\"\ntable_mappings[\"gold\"][\"fact_invoice_period\"] = \"gold.gold_cw_fact_invoice_period\"\n\n# Create entity configurations for gold processing with ConnectWise-specific settings\nentity_configs = {\n    \"agreement\": {\n        \"source\": \"connectwise\",\n        \"surrogate_keys\": [\n            {\"name\": \"AgreementSK\", \"business_keys\": [\"id\"]}\n        ],\n        \"business_keys\": [\n            {\"name\": \"AgreementBusinessKey\", \"source_columns\": [\"id\"]}\n        ],\n        \"calculated_columns\": {\n            \"estimated_monthly_revenue\": \"CASE WHEN applicationUnits = 'Amount' THEN COALESCE(applicationLimit, 0) ELSE 0 END\"\n        },\n        # ConnectWise-specific transform settings\n        \"gold_transforms\": {\n            \"fact_agreement_period\": {\n                \"date_spine\": {\n                    \"start\": \"2020-01-01\",\n                    \"frequency\": \"month\"\n                },\n                \"metrics\": [\n                    \"is_active_period\",\n                    \"is_new_agreement\", \n                    \"is_churned_agreement\",\n                    \"monthly_revenue\",\n                    \"prorated_revenue\",\n                    \"months_since_start\",\n                    \"revenue_change\",\n                    \"cumulative_revenue\"\n                ],\n                \"keys\": [\n                    {\"name\": \"AgreementPeriodSK\", \"type\": \"hash\", \"source_columns\": [\"id\", \"period_start\"]}\n                ]\n            },\n            \"fact_agreement_summary\": {\n                \"metrics\": [\n                    \"lifetime_days\",\n                    \"lifetime_months\",\n                    \"estimated_lifetime_value\",\n                    \"actual_total_revenue\",\n                    \"actual_avg_monthly_revenue\",\n                    \"active_periods\"\n                ],\n                \"keys\": [\n                    {\"name\": \"AgreementSummarySK\", \"type\": \"hash\", \"source_columns\": [\"id\"]}\n                ]\n            }\n        }\n    },\n    \"invoice\": {\n        \"source\": \"connectwise\",\n        \"surrogate_keys\": [\n            {\"name\": \"InvoiceSK\", \"business_keys\": [\"id\"]}\n        ],\n        \"business_keys\": [\n            {\"name\": \"InvoiceBusinessKey\", \"source_columns\": [\"id\"]}\n        ],\n        \"calculated_columns\": {},\n        # ConnectWise-specific invoice transform settings\n        \"enable_period_facts\": True,\n        \"period_type\": \"month\"\n    }\n}\n\n# Add basic configs for other entities without specialized transforms\nfor entity in silver_table_mapping.keys():\n    if entity not in entity_configs:\n        entity_configs[entity] = {\n            \"source\": \"connectwise\",\n            \"surrogate_keys\": [\n                {\"name\": f\"{entity.title()}SK\", \"business_keys\": [\"id\"]}\n            ],\n            \"business_keys\": [\n                {\"name\": f\"{entity.title()}BusinessKey\", \"source_columns\": [\"id\"]}\n            ],\n            \"calculated_columns\": {}\n        }\n\nconfig = {\"entities\": entity_configs}\n\nprint(f\"Processing entities: {list(entity_configs.keys())}\")\nprint(\"Will use ConnectWise-specific transforms for agreement and invoice entities\")\n\n# Run Gold layer with proper table mappings\nrun_etl_pipeline(\n    integrations=[\"connectwise\"],\n    layers=[\"gold\"],\n    config=config,\n    table_mappings=table_mappings\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Gold Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gold tables\n",
    "gold_tables = spark.sql(\"SHOW TABLES IN gold\").collect()\n",
    "print(f\"Found {len(gold_tables)} tables in gold schema:\")\n",
    "\n",
    "for row in gold_tables:\n",
    "    table_name = row.tableName\n",
    "    full_table_name = f\"gold.{table_name}\"\n",
    "    df = spark.sql(f\"SELECT * FROM {full_table_name}\")\n",
    "    count = df.count()\n",
    "    print(f\"\\n{full_table_name}:\")\n",
    "    print(f\"  Rows: {count:,}\")\n",
    "    print(f\"  Columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Show a few sample columns with data\n",
    "    sample_cols = df.columns[:5]\n",
    "    if \"id\" in df.columns and \"id\" not in sample_cols:\n",
    "        sample_cols.append(\"id\")\n",
    "    if any(\"SK\" in col for col in df.columns):\n",
    "        sk_col = next(col for col in df.columns if \"SK\" in col)\n",
    "        if sk_col not in sample_cols:\n",
    "            sample_cols.append(sk_col)\n",
    "    \n",
    "    print(f\"  Sample data ({', '.join(sample_cols)}):\")\n",
    "    df.select(*sample_cols).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Gold Layer Processing Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get row counts for each schema\n",
    "for schema in [\"bronze\", \"silver\", \"gold\"]:\n",
    "    tables = spark.sql(f\"SHOW TABLES IN {schema}\").collect()\n",
    "    total_rows = 0\n",
    "    table_details = []\n",
    "    \n",
    "    for row in tables:\n",
    "        table_name = row.tableName\n",
    "        full_name = f\"{schema}.{table_name}\"\n",
    "        count = spark.sql(f\"SELECT COUNT(*) FROM {full_name}\").collect()[0][0]\n",
    "        total_rows += count\n",
    "        table_details.append((table_name, count))\n",
    "    \n",
    "    print(f\"\\n{schema.upper()} Schema:\")\n",
    "    print(f\"  Tables: {len(tables)}\")\n",
    "    print(f\"  Total rows: {total_rows:,}\")\n",
    "    for table, count in sorted(table_details):\n",
    "        print(f\"    - {table}: {count:,} rows\")\n",
    "\n",
    "print(\"\\nâœ… Gold layer complete - ready for reporting and analytics!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}