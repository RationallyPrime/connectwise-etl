[project]
name = "unified-etl-connectwise"
version = "1.0.0"
description = "ConnectWise PSA adapter for unified ETL framework"
authors = [{name = "HÃ¡kon Freyr Gunnarsson", email = "hakonf@wise.is"}]
requires-python = ">=3.11"
dependencies = [
    "unified-etl-core",
    "requests>=2.28.0",
    "tenacity>=8.0.0",
    "pandas>=1.5.0",
]

[tool.uv.sources]
unified-etl-core = { workspace = true }

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.datamodel-codegen]
target-python-version = "3.11"
base-class = "sparkdantic.SparkModel"
input-file-type = "openapi"
output-model-type = "pydantic_v2.BaseModel"
use-standard-collections = true
use-schema-description = true
use-field-description = true
field-include-all-keys = true
field-constraints = true
strict-nullable = true
collapse-root-models = true
validate-configuration = true
use-model-config = true
capitalize-enum-members = true
use-union-operator = true

# PSA-specific: Preserve camelCase field names
snake-case-field = false
aliased-fields = true
use-annotated = false
strip-default-none = false

# Output formatting
output-model-sorted = true
wrap-string-literal = false
reuse-model = true

# Enums handling
reuse-enum = true
enum-field-as-literal = "all"
use-subclass-enum = true

# OpenAPI-specific options
openapi-scopes = ["schemas"]

[tool.hatch.build.targets.wheel]
packages = ["src/unified_etl_connectwise"]

[tool.hatch.build]
include = [
    "src/unified_etl_connectwise/**/*.py",
    "src/unified_etl_connectwise/**/*.yaml",
]

# Duplicate section removed - using the first one with complete config